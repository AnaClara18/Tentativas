{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c67b9-0416-4e0a-a3f6-aac7a931f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class ConsolidadorDataFrame:\n",
    "\n",
    "\n",
    "    \n",
    "    #Função de inicialização da classe que é chamada automaticamente quando a classe é instanciada\n",
    "    def __init__ (self):\n",
    "        #...\n",
    "        return        \n",
    "\n",
    "    \n",
    "    \n",
    "    def filtrar_dataframe (self, caminho_arquivo_csv, nome_coluna, valor_procurado, codificacao='iso-8859-1', separador=';'):\n",
    "\n",
    "        display (f'Processando arquivo: {caminho_arquivo_csv}')\n",
    "        \n",
    "        indice_ultimo_separador = caminho_arquivo_csv.rfind(\"/\")\n",
    "        nome_arquivo = caminho_arquivo_csv [indice_ultimo_separador+1:-4] \n",
    "    \n",
    "        ano = int(nome_arquivo[:4])\n",
    "        mes = int(nome_arquivo[4:6])        \n",
    "        \n",
    "        df = pd.read_csv(caminho_arquivo_csv, encoding=codificacao, sep=separador)\n",
    "    \n",
    "        df_filtrado = df[df[nome_coluna].str.contains(valor_procurado, case=False, na=False)]\n",
    "    \n",
    "        df_filtrado['ano'] = ano\n",
    "        df_filtrado['mes'] = mes\n",
    "        \n",
    "        return df_filtrado\n",
    "\n",
    "\n",
    "    \n",
    "    def percorre_diretorio_CSV(self, diretorio, texto_filtro_arquivo, caminho_destino_csv,  nome_coluna, valor_procurado, tamanho_bloco=12, codificacao='iso-8859-1', separador=';', ano_inicio=None):\n",
    "    \n",
    "        #Declarando variáveis globais para o escopo da função percorre_diretorio_CSV\n",
    "        #elas serão usadas na função salvar_e_reiniciar_parte\n",
    "        global numero_parte\n",
    "        global contador_arquivos_processados    \n",
    "        global df_consolidado\n",
    "    \n",
    "        \n",
    "        #Variáveis para calcular tamanho da parte    \n",
    "        numero_parte = 0        \n",
    "        contador_arquivos_processados = 0\n",
    "    \n",
    "        \n",
    "        #Dataframe para consolidação\n",
    "        df_consolidado = pd.DataFrame()\n",
    "    \n",
    "        \n",
    "        \n",
    "        def salvar_e_reiniciar_parte():\n",
    "    \n",
    "            #Referenciando as variáveis globais criadas pela função pai percorre_diretorio_CSV\n",
    "            global numero_parte\n",
    "            global contador_arquivos_processados\n",
    "            global df_consolidado        \n",
    "            \n",
    "            numero_parte += 1\n",
    "                \n",
    "            #colocar número da parte no nome do CSV consolidado       \n",
    "            nome_destino_csv = f'{caminho_destino_csv[:-4]}_parte_{numero_parte}{caminho_destino_csv[-4:]}'\n",
    "    \n",
    "            display (f'*********************** Salvando arquivo de parte: {nome_destino_csv}')\n",
    "            \n",
    "            #Salva o bloco atual\n",
    "            df_consolidado.to_csv(nome_destino_csv, index=False)\n",
    "            \n",
    "            #Reinicia o Dataframe\n",
    "            df_consolidado = pd.DataFrame()\n",
    "    \n",
    "            contador_arquivos_processados = 0\n",
    "    \n",
    "        \n",
    "        \n",
    "        # Lista todos os arquivos no diretório\n",
    "        arquivos = os.listdir(diretorio)    \n",
    "        \n",
    "        # Filtra apenas os subdiretorios, excluindo arquivos\n",
    "        subdiretorios = [arquivo for arquivo in arquivos if os.path.isdir(os.path.join(diretorio, arquivo))]\n",
    "    \n",
    "        \n",
    "        # Ordena os subdiretórios alfabeticamente\n",
    "        subdiretorios_ordenados = sorted(subdiretorios)\n",
    "        \n",
    "        \n",
    "        # Itera a lista de subdiretorios\n",
    "        for subdiretorio in subdiretorios_ordenados:\n",
    "\n",
    "            ano_subdiretorio = int(subdiretorio[0:4])\n",
    "            \n",
    "            if (ano_inicio == None) or (ano_subdiretorio >= ano_inicio):\n",
    "            \n",
    "                contador_arquivos_processados += 1\n",
    "                \n",
    "                caminho_completo = os.path.join(diretorio, subdiretorio)\n",
    "                \n",
    "                arquivos_subdiretorio = os.listdir(caminho_completo) \n",
    "        \n",
    "                lista_arquivo = [arquivo for arquivo in arquivos_subdiretorio if arquivo.lower().find(texto_filtro_arquivo) != -1]\n",
    "        \n",
    "                if len(lista_arquivo) == 1:\n",
    "                    \n",
    "                    caminho_arquivo_csv = lista_arquivo[0]\n",
    "        \n",
    "                    caminho_completo_arquivo_csv = os.path.join(caminho_completo, caminho_arquivo_csv)                        \n",
    "        \n",
    "                    df_total = self.filtrar_dataframe (caminho_completo_arquivo_csv, nome_coluna, valor_procurado, codificacao, separador)\n",
    "        \n",
    "                    # Concatena o DataFrame atual com o DataFrame consolidado\n",
    "                    df_consolidado = pd.concat([df_consolidado, df_total], ignore_index=True)\n",
    "                \n",
    "                else:\n",
    "        \n",
    "                    display (f'ATENÇÃO: Mais ou nenhum arquivo csv no subdiretório {caminho_completo}')\n",
    "        \n",
    "                \n",
    "                #Se formou uma parte com TAMANHO_BLOCO arquivos a serem salvos\n",
    "                if contador_arquivos_processados >= tamanho_bloco:\n",
    "        \n",
    "                    salvar_e_reiniciar_parte()\n",
    "    \n",
    "        \n",
    "        #Se existe um resto de arquivos que ainda não foram salvos em uma parte\n",
    "        if contador_arquivos_processados > 0:\n",
    "    \n",
    "                salvar_e_reiniciar_parte()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def consolida_partes(self, diretorio, texto_filtro_arquivo, destino_csv):\n",
    "    \n",
    "        #Dataframe para consolidação\n",
    "        df_consolidado_total= pd.DataFrame()\n",
    "    \n",
    "        # Lista todos os arquivos no diretório    \n",
    "        arquivos_partes = os.listdir(diretorio) \n",
    "        arquivos_partes = [arquivo for arquivo in arquivos_partes if arquivo.lower().find(texto_filtro_arquivo) != -1]\n",
    "    \n",
    "        # Itera a lista de arquivos\n",
    "        for arquivo_parte in arquivos_partes:\n",
    "                    \n",
    "            caminho_completo_arquivo_parte = os.path.join(diretorio, arquivo_parte) \n",
    "    \n",
    "            display (f'Processando arquivo: {arquivo_parte}')\n",
    "            \n",
    "            #df_consolidado = pd.read_csv(caminho_completo_arquivo_parte, encoding='iso-8859-1', sep=';')\n",
    "            df_consolidado = pd.read_csv(caminho_completo_arquivo_parte)\n",
    "    \n",
    "            # Concatena o DataFrame atual com o DataFrame consolidado\n",
    "            df_consolidado_total = pd.concat([df_consolidado_total, df_consolidado], ignore_index=True)\n",
    "                    \n",
    "    \n",
    "        display (f'Vai salvar....')\n",
    "    \n",
    "        #Salva o arquivo consolidado com todos os anos\n",
    "        df_consolidado_total.to_csv(destino_csv, index=False)\n",
    "    \n",
    "    \n",
    "        display (f'Finalizado!')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
